{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d9498db-c77a-4c3b-9801-a70f5d39512e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 KB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib in /home/shailesh/Desktop/VritEducation/.vritenv/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
      "Collecting click\n",
      "  Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Installing collected packages: tqdm, regex, click, nltk\n",
      "Successfully installed click-8.1.7 nltk-3.9.1 regex-2024.11.6 tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8243ae23-225e-4042-a25a-68f87db99ce5",
   "metadata": {},
   "source": [
    "## Text Preprocessing\n",
    "\n",
    "Text preprocessing is an essential step in natural language processing (NLP) tasks. It involves transforming raw text data into a format that is more suitable for analysis and machine learning algorithms. In this tutorial, we will cover various common techniques for text preprocessing. Let's dive in!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3faf1c-d2fd-46e9-8042-95c1555add81",
   "metadata": {},
   "source": [
    "### Lowercasing\n",
    "Converting all text to lowercase can help to normalize the data and reduce the vocabulary size. It ensures that words in different cases are treated as the same word. For example, \"apple\" and \"Apple\" will both be transformed to \"apple\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0359a82-0421-4384-a046-9f197b4e3dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"Hello, I am your AI Sathi R@3#.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fbe67c6-a66b-420d-8d56-a2c00c1764c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello, i am your ai sathi r@3#.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_sent = sent.lower()\n",
    "lower_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79e2531-929d-4e97-952c-80fa3a4f7f39",
   "metadata": {},
   "source": [
    "### Removal of Punctuation and Special Characters\n",
    "Punctuation marks and special characters often do not add much meaning to the text and can be safely removed. Common punctuation marks include periods, commas, question marks, and exclamation marks. You can use regular expressions or string operations to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3abefc20-7ede-46ff-a48c-a1dc75bcd955",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_punctuation = ['.', ',', ':', ';', '!', '?', '(', ')', '\"', \"'\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b79b234-48a5-400b-b703-8b36b695ae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = \"\"\n",
    "for each in lower_sent:\n",
    "    if each not in common_punctuation:\n",
    "        result += each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e97f189-42d4-46fa-93fb-f168336b832c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello i am your ai sathi r3'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "cleaned = re.sub(r'[^\\w\\s]','', lower_sent)\n",
    "cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4932851c-26b3-482b-8ffa-b425b44b314d",
   "metadata": {},
   "source": [
    "### Stop Word Removal:\n",
    "Stop words are commonly occurring words in a language, such as \"a,\" \"an,\" \"the,\" \"is,\" and \"in.\" These words provide little semantic value and can be removed to reduce noise in the data. Libraries like NLTK provide a list of predefined stop words for different languages.\n",
    "\n",
    "Before using the code make sure you downloaded all the stopwords uning the first shell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ade27058-45d4-4a29-a87c-594f7f3adb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/shailesh/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0f115fd-2dbf-48a8-8089-7dc1c080251a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c89c766-d37b-49ea-b4fe-5ff0fc56da35",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_eng = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a97b4c-8309-4c4f-8863-245448646d82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
