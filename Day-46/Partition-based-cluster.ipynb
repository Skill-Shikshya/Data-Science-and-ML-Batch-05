{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "012380fd-c27b-4deb-bace-37b35f4cdecb",
   "metadata": {},
   "source": [
    "# Partition-based clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a4cfc2-ace2-4ae1-b6f1-4ce1f9c53124",
   "metadata": {},
   "source": [
    "## _K_-Means Algorithm\n",
    "_K_-Means is an iterative algorithm that tries to separate a given dataset into _K_ number of clusters and minimize the distance between data points and their respective cluster centroid. It is one of the simplest and popular clustering algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf340b2-f49d-4d90-8783-7903d74eaa65",
   "metadata": {},
   "source": [
    "The whole process of _K_-Means is summarized in the following few steps:\n",
    "\n",
    "__Input:__ $$ \\mathbf x_1, \\mathbf x_2, \\dots , \\mathbf x_N $$\n",
    "\n",
    "where,\n",
    "\n",
    "- $N$ = total number of samples\n",
    "- $\\mathbf x_i$ = $i^{th}$ sample from the dataset $X$ where $\\mathbf x_i \\in \\mathbb R^Z$\n",
    "- $Z$ = total number of features/attributes\n",
    "\n",
    "__Output:__ Vector $\\mathbf{c}_N$ of cluster assignments in $\\mathbb R^N$, and $K$ number of mean vectors $\\boldsymbol \\mu_k$ where matrix of all $K$ means is in $\\mathbb R^{K \\times Z}$\n",
    "\n",
    "__Steps:__\n",
    "\n",
    "1. Specify the number of clusters $K$.\n",
    "2. Initialize the cluster centroids with any initialization methods.\n",
    "\n",
    "3. Compute the distance between each point and each cluster centroids(Euclidean distance metric is a popular choice) Where distance is a vector in $\\mathbb R^{N} $ for all data points and for all $K$ centroids, distances will be a matrix in $\\mathbb R^{K \\times N} $.\n",
    "\n",
    "$$ distance = \\|\\mathbf{x}_i - \\boldsymbol\\mu_k \\|_2^2$$\n",
    "\n",
    "\n",
    "4. Assign each point to the closest cluster centroid (minimum distance).\n",
    "\n",
    "5. Compute the new cluster centroid for each cluster by taking the mean of all the data points in that cluster.\n",
    "6. Repeat steps 3-5 until there is no change in the cluster centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f3188cc-5217-42b2-8932-c9b5a58152ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"450\"\n",
       "            src=\"https://kmeans.netlify.app\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x756884572ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title **Experimental Cell: KMeans Clustering**\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import IFrame\n",
    "\n",
    "display(IFrame('https://kmeans.netlify.app', height=450, width='100%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fd16cf-1a66-41a9-827a-c9622dfd9a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05e6a357-10ed-4e07-848a-e447ac78a513",
   "metadata": {},
   "source": [
    "## _K_-Means Objective Function\n",
    "\n",
    "\n",
    "The _K_-Means algorithm's objective is to minimize the sum of squared distance between data points and the centroid within a cluster and maximize the distance between different clusters.\n",
    "\n",
    "We can use the following objective function to minimize the distance between data points and the centroid which makes a tighter cluster and distance between other clusters are automatically maximized.\n",
    "$$\n",
    "\\mathcal J =\\underset{\\boldsymbol \\mu, \\boldsymbol c}{\\arg\\min} \\sum_{k=1}^K \\sum_{i = 1}^N \\mathbb{1} \\{\\boldsymbol c_i = k\\} \\|\\mathbf{x}_i - \\boldsymbol{\\mu}_k \\|^2_2 \\tag{1}\\\\\n",
    "$$\n",
    "\n",
    "\n",
    "Where,\n",
    "* $\\mathcal J$ is the objective function.\n",
    "\n",
    "* $K$ is the number of clusters and $N$ is the total number of samples.\n",
    "\n",
    "* $\\mathbf{x}_i$ is the vector of $i^{th}$ data point.\n",
    "\n",
    "* $\\boldsymbol c$ is a cluster assignments vector which contains the index of $k^{th}$ cluster in which $i^{th}$ data point belongs to.\n",
    "\n",
    "* $\\mathbb{1} \\{\\boldsymbol c_i = k\\}$ is an indicator function of a set which equals to 1 if the $\\boldsymbol c_i = k$ else 0.\n",
    "\n",
    "* $\\boldsymbol \\mu_k$ is the vector of $k^{th}$ cluster centroids:\n",
    "$$\n",
    "\\boldsymbol \\mu_k = \\frac{\\sum^N_{i : \\boldsymbol c_i=k} \\mathbf{x_i}}{|\\boldsymbol c_{i=k}|}. \\tag{2}\n",
    "\\\\\n",
    "$$\n",
    "\n",
    "In a plain language, above objective function in equation (1) finds the $\\boldsymbol \\mu$ and $\\boldsymbol c$ which minimizes the distance between $\\mathbf x_i$ and $\\boldsymbol \\mu_k$ where the given $\\mathbf x_i$ is in cluster assignments $\\boldsymbol c_{i=k}$.\n",
    "\n",
    "*Note: The objective function of K-Means is referred to as Sum of Squared Error (SSE) or the Residual Squared Error (RSS).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce179d44-1433-464d-8084-92b57cf9e7fa",
   "metadata": {},
   "source": [
    "Since _K_-Means is an **iterative algorithm**, it's objective function cannot be optimized by taking derivatives and setting zero. **We have to use some iterative optimization algorithms like Gradient Descent, but the problem here is our objective function is composed of two dependent unknowns: $\\boldsymbol \\mu$ and $\\boldsymbol c$. Gradient Descent algorithm attempts to update all parameters at same time but we cannot find their best values at the same time to minimize our objective function $\\mathcal J$**. However, we can fix the value of $\\boldsymbol \\mu$ and find the best $\\boldsymbol c$, and after that, we can fix the value of $\\boldsymbol c$ and find the best $\\boldsymbol \\mu$.\n",
    "\n",
    "This process of holding on one set of parameters fixed and optimizing the other, and vice-versa is called the **Coordinate Descent** optimization approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11e5f25-0be4-4ee6-ac39-6edd7c4acdad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
